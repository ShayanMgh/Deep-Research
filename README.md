# ğŸ§  LLaMA 3.2 Local Research Assistant (Ollama + Gradio)

This project is a fully local, private AI assistant that uses **LLaMA 3.2** running with [Ollama](https://ollama.com/) to:

- Answer factual questions
- Dynamically call tools like web search or ticket pricing
- Display responses in an interactive Gradio chat UI

> âœ… No API keys, no cloud, no cost â€“ 100% local!

---

## ğŸ“¸ Demo

![Screenshot](./screenshot.png)

---

## ğŸš€ Features

- ğŸ” **Web search tool** using DuckDuckGo + BeautifulSoup
- ğŸ§¾ **Summarization** via LLaMA 3.2's local language reasoning
- âœˆï¸ Optional **ticket price lookup tool** example
- ğŸ§  Built on Ollama's tool-calling capabilities
- ğŸ’¬ Fast chat UI powered by Gradio

---
